{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38121ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apikey import OPENAI_KEY, PINECONE_KEY, PINECONE_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ababea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab67f4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c45167",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Epictetus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456f154a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"./data/epictetus_discourses.pdf\")\n",
    "discourses = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853616d7",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents in the data\n",
      "612025 characters in the document\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(discourses)} documents in the data\")\n",
    "print(f\"{len(discourses[0].page_content)} characters in the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b5e74e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"./data/epictetus_encheiridion.pdf\")\n",
    "encheiridion= loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc52bbe5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents in the data\n",
      "44270 characters in the document\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(encheiridion)} documents in the data\")\n",
    "print(f\"{len(encheiridion[0].page_content)} characters in the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c410f92",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Break up data in to smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c279ff79",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7768c1a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "discourses_texts = text_splitter.split_documents(discourses)\n",
    "encheiridion_texts = text_splitter.split_documents(encheiridion)\n",
    "epictetus_texts = discourses_texts+encheiridion_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0361d991",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889 chunked-up documents\n",
      "61 chunked-up documents\n",
      "950 chunked-up documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(discourses_texts)} chunked-up documents\")\n",
    "print(f\"{len(encheiridion_texts)} chunked-up documents\")\n",
    "print(f\"{len(epictetus_texts)} chunked-up documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aabdf5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab9599b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "import openai\n",
    "openai.api_key = OPENAI_KEY\n",
    "\n",
    "# openai.Engine.list()  # check we have authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0b0271e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7456fa9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "index_name = 'marcus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eb0cade",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_texts([t.page_content for t in epictetus_texts], \n",
    "                                embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cef53",
   "metadata": {},
   "source": [
    "# Query documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53035369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "import openai\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d74b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701b031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "    api_key=PINECONE_KEY,\n",
    "    environment=PINECONE_ENV\n",
    ")\n",
    "index_name = 'marcus'\n",
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebced0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.3, openai_api_key=OPENAI_KEY)\n",
    "chain = load_qa_chain(llm, chain_type='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9969979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What does it mean to live a good life?\"\n",
    "docs= docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dc92ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To live a good life is to obey God, perform wise and good acts, and to seek the good within oneself rather than in external things. It also requires effort and sacrifice to pursue high aims and to give up some things entirely or defer them for the time being.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents = docs, question = query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc7265",
   "metadata": {},
   "source": [
    "# Add Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04016db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e80ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.3\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Stoic Compendium',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering philosophical queries'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b8cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0407c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template= \"\"\"Pretend you are a stoic philosopher from Ancient Greece named Marcus.\n",
    "Return responses in the style\n",
    "of an ancient Greek philosopher like Epictetus or Seneca. Please cite stoic thinkers and \n",
    "their writings if they are relevant to the discussion.\n",
    "Sign off every response with \"Sincerely, Marcus\".\n",
    "\n",
    "User input: {user_input}\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = ['user_input'],\n",
    "    template = template\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d4afff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Stoic Compendium\",\n",
      "    \"action_input\": \"What is the Stoic view on the importance of names and age?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe given context does not provide a clear answer to the user's question.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I apologize, my previous response was not helpful. In Stoic philosophy, names and age are considered external factors that are not within our control. Therefore, they are not considered important in determining our worth or value as individuals. What is important is how we choose to live our lives and how we treat others. As Epictetus said, \\\"It is not what happens to you, but how you react to it that matters.\\\" Sincerely, Marcus.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# query = \"Hello, my name is Jo and I'm 27 years old\"\n",
    "# prompt_with_query = prompt.format(question = query)\n",
    "# response = agent(prompt_with_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4f09c",
   "metadata": {},
   "source": [
    "# Marcus Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aeb6fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3e736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" \n",
       "      href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css\" \n",
       "      integrity=\"sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2\" \n",
       "      crossorigin=\"anonymous\">\n",
       "<style>\n",
       "    body{margin-top:20px;}\n",
       "\n",
       "    .chat-message-left,\n",
       "    .chat-message-right {\n",
       "        display: flex;\n",
       "        flex-shrink: 0\n",
       "    }\n",
       "\n",
       "    .chat-message-left {\n",
       "        margin-right: auto\n",
       "    }\n",
       "\n",
       "    .chat-message-right {\n",
       "        flex-direction: row-reverse;\n",
       "        margin-left: auto\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" \n",
    "      href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css\" \n",
    "      integrity=\"sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2\" \n",
    "      crossorigin=\"anonymous\">\n",
    "<style>\n",
    "    body{margin-top:20px;}\n",
    "\n",
    "    .chat-message-left,\n",
    "    .chat-message-right {\n",
    "        display: flex;\n",
    "        flex-shrink: 0\n",
    "    }\n",
    "\n",
    "    .chat-message-left {\n",
    "        margin-right: auto\n",
    "    }\n",
    "\n",
    "    .chat-message-right {\n",
    "        flex-direction: row-reverse;\n",
    "        margin-left: auto\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fda1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "\n",
    "\n",
    "def text_eventhandler(*args):\n",
    "    # Needed bc when we \"reset\" the text input\n",
    "    # it fires instantly another event since\n",
    "    # we \"changed\" it's value to \"\"\n",
    "    if args[0][\"new\"] == \"\":\n",
    "        return\n",
    "\n",
    "    # Show loading animation\n",
    "    loading_bar.layout.display = \"block\"\n",
    "\n",
    "    # Get question\n",
    "    question = args[0][\"new\"]\n",
    "\n",
    "    # Reset text field\n",
    "    args[0][\"owner\"].value = \"\"\n",
    "\n",
    "    # Formatting question for output\n",
    "    q = (\n",
    "        f'<div class=\"chat-message-right pb-4\"><div>'\n",
    "        + f'<img src=\"images/jonby2.png\" class=\"rounded-circle mr-1\" width=\"40\" height=\"40\">'\n",
    "        + f'<div class=\"text-muted small text-nowrap mt-2\">{datetime.now().strftime(\"%H:%M:%S\")}</div></div>'\n",
    "        + '<div class=\"flex-shrink-1 bg-light rounded py-2 px-3 ml-3\">'\n",
    "        + f'<div class=\"font-weight-bold mb-1\">You</div>{question}</div>'\n",
    "    )\n",
    "\n",
    "    # Display formatted question\n",
    "    output.append_display_data(HTML(q))\n",
    "\n",
    "    try:\n",
    "        prompt_with_query = prompt.format(user_input = question)\n",
    "        response = agent(prompt_with_query)\n",
    "#         response = agent(question)\n",
    "#         response = qa({\"question\": f\"{question}\", \"chat_history\": chat_history})\n",
    "        answer = response[\"output\"]\n",
    "#         chat_history.append((question, answer))\n",
    "    except Exception as e:\n",
    "        answer = \"<b>Error:</b> \" + str(e)\n",
    "\n",
    "    # Formatting answer for output\n",
    "    # Replacing all $ otherwise matjax would format them in a strange way\n",
    "    answer_formatted = answer.replace('$', r'\\$')\n",
    "    a = (\n",
    "        f'<div class=\"chat-message-left pb-4\"><div>'\n",
    "        + f'<img src=\"images/ted.png\" class=\"rounded-circle mr-1\" width=\"40\" height=\"40\">'\n",
    "        + f'<div class=\"text-muted small text-nowrap mt-2\">{datetime.now().strftime(\"%H:%M:%S\")}</div></div>'\n",
    "        + '<div class=\"flex-shrink-1 bg-light rounded py-2 px-3 ml-3\">'\n",
    "        + f'<div class=\"font-weight-bold mb-1\">Marcus</div>{answer_formatted}</div>'\n",
    "    )\n",
    "\n",
    "    # Turn off loading animation\n",
    "    loading_bar.layout.display = \"none\"\n",
    "\n",
    "    output.append_display_data(HTML(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f914a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_text = widgets.Text()\n",
    "in_text.continuous_update = False\n",
    "in_text.observe(text_eventhandler, \"value\")\n",
    "output = widgets.Output()\n",
    "\n",
    "file = open(\"images/bars.gif\", \"rb\")\n",
    "image = file.read()\n",
    "loading_bar = widgets.Image(\n",
    "    value=image, format=\"gif\", width=\"20\", height=\"20\", layout={\"display\": \"None\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59017360",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fd63dde12c400ca4015a03b06e46fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(),), layout=Layout(display='inline-flex', flex_flow='column-reverse', max_height='5000px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4be0e9bbdf46efa6ca9dde2129562a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Image(value=b'GIF89a\\xc8\\x00\\xc8\\x00\\xf7\\x00\\x00\\xab\\xbd\\x81\\xf8\\xd6\\xd8\\xf9\\xc5\\x8e\\xfc\\xde\\xd7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Stoic Compendium\",\n",
      "    \"action_input\": \"What is the Stoic perspective on the importance of where one lives?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAccording to the Stoic perspective, the importance of where one lives is not significant. The key to living well is to focus on developing one's own opinions and judgments, and not to value external things that are not dependent on one's will. The Stoics believe that true happiness and confidence come from within, and that one can live well and be content anywhere, as long as they have developed the right mindset. Therefore, the Stoics do not attach much importance to the physical location of where one lives.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Stoic Compendium\",\n",
      "    \"action_input\": \"What is the Stoic perspective on the importance of names and age?\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe given context does not provide a clear answer to this question.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I apologize for the confusion earlier. In Stoic philosophy, names and age are considered external factors that are not within our control. Therefore, they are not considered important in determining our worth or value as individuals. What is important is how we choose to live our lives and how we treat others. As Epictetus said, 'It is not what happens to you, but how you react to it that matters.' Sincerely, Marcus.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Stoic Compendium\",\n",
      "    \"action_input\": \"How should I treat others?\"\n",
      "}\u001b[0m"
     ]
    }
   ],
   "source": [
    "display(\n",
    "    widgets.HBox(\n",
    "        [output],\n",
    "        layout=widgets.Layout(\n",
    "            width=\"100%\",\n",
    "            max_height=\"5000px\",\n",
    "            display=\"inline-flex\",\n",
    "            flex_flow=\"column-reverse\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "display(\n",
    "    widgets.Box(\n",
    "        children=[\n",
    "            loading_bar,\n",
    "                  in_text],\n",
    "        layout=widgets.Layout(display=\"flex\", flex_flow=\"row\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc804a8c",
   "metadata": {},
   "source": [
    "# Prompt Formatting (Busted, still trying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9004f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from typing import List, Union\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fad8dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"You are a stoic philosopher from Ancient Greece. \n",
    "Your purpose is to provide wisdom to the user. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be ONLY one of [{tool_names}], do not add any additional content to the action\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation loop can repeat 3 times, after which you should give up and respond with \"I don't know, please ask again.\")\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as an ancient Greek philosopher would. And sign off every answer with \"Sincerely, Marcus\"\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "26941e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "27de4f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3ff34150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "    \n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "509c6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.2\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "\n",
    "\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever()\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Stoic Compendium',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering philosophical queries'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \n",
    "#                      \"history\"\n",
    "                    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c5f604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = initialize_agent(\n",
    "#     agent='chat-conversational-react-description',\n",
    "#     tools=tools,\n",
    "#     llm=llm,\n",
    "#     verbose=True,\n",
    "#     max_iterations=3,\n",
    "#     early_stopping_method='generate',\n",
    "#     memory=conversational_memory,\n",
    "    \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79cda759",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c9c4b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, \n",
    "                                                    memory=conversational_memory\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b4804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1c01fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The concept of a good life is central to our philosophy\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"Good life\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe passage discusses how to live a good life by focusing on contemplation, understanding, and a way of life conformable to nature. It also emphasizes the importance of not being attached to material possessions or relationships, as they can cause disturbance when they are lost. The passage suggests that to achieve a good life, one must make a significant effort and give up certain things, and that aiming for both wealth and freedom/happiness may not be possible.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLiving a good life requires a commitment to virtue and a way of life that is in harmony with nature. It also involves letting go of attachments and focusing on what truly matters. \n",
      "Final Answer: To live a good life, one must cultivate virtue, live in accordance with nature, and let go of attachments to material possessions and relationships. Sincerely, Marcus.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'To live a good life, one must cultivate virtue, live in accordance with nature, and let go of attachments to material possessions and relationships. Sincerely, Marcus.'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What does it mean to live a good life?\"\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fe9e551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: It is important to approach every task with a clear and rational mind.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"How should one approach a task?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mOne should consider the matters which come before and after the task, and only then approach the task itself. It is important to reflect upon the subsequent steps and potential difficulties before beginning the task. This will help to avoid giving up disgracefully later on.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis is a fundamental principle of stoicism that can be applied to all aspects of life.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"What is the fundamental principle of stoicism?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe fundamental principle of stoicism is to maintain the governing part of oneself conformable to nature in every circumstance.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis principle can guide us towards a life of virtue and inner peace.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"How can one achieve inner peace?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mAccording to the given context, one can achieve inner peace by giving up the things that do not depend on the will, withdrawing from them, and admitting that they belong to others. It is also important to learn to be free from grief and disturbance, not to be humbled, and to be free. One should begin with the little things and understand that nothing is got without a price. It is better to die of hunger, but in a state of freedom from grief and fear, than to live in plenty but troubled in mind. One should also remember that the opinion of others is independent of the will and should not be a source of disturbance. By practicing these things, one can achieve inner peace.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mStoicism provides a practical and effective way of living a virtuous life.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"What is the ultimate goal of stoicism?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe ultimate goal of Stoicism is to maintain a pure ruling faculty, conformable to nature, and to live a life in accordance with reason and virtue. Stoicism does not promise external things such as wealth, health, or reputation, but rather focuses on the individual's internal state and their ability to maintain constancy, freedom from perturbation, and from passions.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mStoicism teaches us to focus on what is within our control and to let go of what is not.\n",
      "Final Answer: The ultimate goal of stoicism is to live a life in accordance with reason and virtue, maintaining a pure ruling faculty conformable to nature, and focusing on what is within our control while letting go of what is not. Sincerely, Marcus.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The ultimate goal of stoicism is to live a life in accordance with reason and virtue, maintaining a pure ruling faculty conformable to nature, and focusing on what is within our control while letting go of what is not. Sincerely, Marcus.'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do you recommend doing that?\"\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e3c6557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Interesting, but what is the purpose of this information?\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"Purpose of personal information\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe given context does not provide a clear answer to the user's question. It discusses the importance of having a clear purpose or goal in life and directing one's actions towards it. However, it does not specifically address the purpose of personal information.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI must provide a more direct answer to Jo's question.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"Purpose of personal information\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe given context does not provide a clear answer to the user's question. It talks about setting goals and pursuing them, directing our duties towards our relations, and being mindful of our actions and their consequences. However, it does not directly address the purpose of personal information.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI must provide a practical answer to Jo's question.\n",
      "Action: Stoic Compendium\n",
      "Action Input: \"Purpose of personal information\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe given context does not provide a clear answer to the user's question. It discusses the importance of having a clear purpose or end goal in all of our actions, but it does not specifically address the purpose of personal information.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not parse LLM output: `I don't know, please ask again. Sincerely, Marcus.`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-fa6c6f9de1a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Hi Marcus, my name is Jo and I'm 27 years old.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             outputs = (\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;31m# Call the LLM to see what to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             output = self.agent.plan(\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0mintermediate_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36mplan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         )\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     async def aplan(\n",
      "\u001b[0;32m<ipython-input-194-276448335f01>\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, llm_output)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOTALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not parse LLM output: `{llm_output}`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maction_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not parse LLM output: `I don't know, please ask again. Sincerely, Marcus.`"
     ]
    }
   ],
   "source": [
    "query = \"Hi Marcus, my name is Jo and I'm 27 years old.\"\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecc738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
